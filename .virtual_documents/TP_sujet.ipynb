!git clone https://github.com/amauryleroy/TP_epu.git


github = False
if github:
    source = '/content/TP_epu/'
else:
    source = '.'








import numpy as np
import os

path = os.path.join(source, 'datasets/')
train_set = np.loadtxt(path + 'CompleteHereByAString', dtype=str)
validation_set = np.loadtxt(path + 'CompleteHereByAString', dtype=str)
test_set = np.loadtxt(path + 'CompleteHereByAString', dtype=str)





print('Train Set - First 5 Patients:')
print('CompleteHereByAList')





train_size = 'CompleteHereByCode'
validation_size = 'CompleteHereByCode'
test_size = 'CompleteHereByCode'

print('Train Set Size:', train_size)
print('Validation Set Size:', validation_size)
print('Test Set Size:', test_size)





import os

data_folder = os.path.join(source, 'data/') # The data is stored in this folder
patients = os.listdir(data_folder) # List of all the patients, thanks to the os library and the listdir function.
print('First 5 Patients in the Data Folder:')
print('CompleteHereByAList')





data_folder_length = 'CompleteHereByCode'
print('Data Folder Length:', data_folder_length)





selected_patient = 'BraTS19_2013_0_1/'
patient_folder = os.path.join(data_folder, selected_patient) # The os.path.join function allows to concatenate two strings, here the path to the data folder and the name of the patient folder
images = os.listdir(patient_folder) # List of all the images of the selected patient
num_images = 'CompleteHereByCode'
print('Number of Images in Patient Folder:', num_images)





num_slices = 'CompleteHereByCode'
print('Number of Z Slices for', selected_patient, ':', num_slices)





print('First 5 Images of', selected_patient, ':')
for image in 'CompleteHereByIterable':
    print(image)





import SimpleITK as sitk
import os

orig_data_path = os.path.join(source,'origin_data/')

patients = ['BraTS19_CBICA_ANP_1', 'BraTS19_CBICA_AWV_1', 'BraTS19_TCIA01_131_1', 'BraTS19_TCIA10_442_1']
modalities = ['_t1', '_t2', '_flair', 't1ce', 'seg']
suffix = '.nii.gz'

patient = patients[0]
modality = modalities[0]

patient_folder = os.path.join(orig_data_path, patient)

# Use SimpleITK to open the NIfTI image
image_path = os.path.join(patient_folder, patient + modality + suffix)
image = sitk.ReadImage(image_path)

# Print the image type
print('Image Type:', type(image))

# Print geometrical information
print('Image Direction:', image.GetDirection())
print('Image Spacing:', image.GetSpacing())
print('Image Origin:', image.GetOrigin())

# Get the pixel value at coordinate (0, 0, 0)
print('Pixel Value at (0, 0, 0):', image.GetPixel(0, 0, 0))

# Get all the metadata information
metadata = image.GetMetaDataKeys()
print('Metadata:')
for key in metadata:
    value = image.GetMetaData(key)
    print('{}: {}'.format(key, value))

# Convert the SimpleITK image to a NumPy array
array = sitk.GetArrayFromImage(image)
print('Array Type:', type(array))
print('Array Shape:', array.shape)
print('Value at (0, 0, 0) in the Array:', array[0, 0, 0])





import matplotlib.pyplot as plt

orig_data_path = os.path.join(source, 'origin_data/')
patient = patients[0]
modality = modalities[0]
patient_folder = os.path.join('''CompleteHere''')
# We use the librairy sitk to open the nifti images
image = sitk.ReadImage(os.path.join('''CompleteHere''', patient + modality + suffix))

orig_array = sitk.GetArrayFromImage(image)
print('Orig array shape : {}'.format('''CompleteHere'''.shape))

###
data_path = os.path.join(source, 'data/')
patient_folder = os.path.join('''CompleteHere''',patient)
z_slice = 35
path = os.path.join('''CompleteHere''', patient + modality + '_z_' + str(z_slice) + suffix)
image = sitk.ReadImage(path)
processed_array = sitk.GetArrayFromImage(image)
print('Processed array shape : {}'.format('''CompleteHere'''.shape))

plt.subplot(1, 2, 1)
plt.imshow('''CompleteHere'''[z_slice*2, :, :], cmap='gray')
plt.title('''CompleteHere''')
plt.subplot(1, 2, 2)
plt.imshow('''CompleteHere''', cmap='gray')
plt.title('''CompleteHere''')









import torch
from torch import nn

def double_conv(in_channels, out_channels):
            return nn.Sequential(
                nn.Conv2d(in_channels, out_channels, 3, padding=1),
                nn.ReLU(inplace=True),
                nn.Conv2d(out_channels, out_channels, 3, padding=1),
                nn.ReLU(inplace=True),
                nn.Dropout(0.5)
            )

def down(in_channels, out_channels):
    return nn.Sequential(
        nn.MaxPool2d(2),
        double_conv(in_channels, out_channels)
    )

class up_block(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(up_block, self).__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.upsample = nn.Sequential(nn.___(scale_factor=2, mode='bilinear', align_corners=True),
                                       nn.___(in_channels,in_channels//2, 2, padding="same"))
        self.up_conv = double_conv(self.in_channels, self.out_channels)

    def forward(self, x, x_skip):
        x = self.upsample(__)
        x = torch.cat([__, __], dim=1)
        x = self.up_conv(__)
        return x

start_channel = 16
class UNet(nn.Module):
    def __init__(self, n_channels, n_classes):
        super(UNet, self).__init__()
        self.n_channels = n_channels
        self.n_classes = n_classes

        # Define blocks of convolutions
        self.inc = double_conv(n_channels, start_channel)
        self.down1 = down(start_channel, __)
        self.down2 = down(__, __)
        self.down3 = down(__, __)
        self.up1 = up_block(__, __)
        self.up2 = up_block(__, __)
        self.up3 = up_block(__, start_channel)
        self.outc = nn.Conv2d(start_channel, n_classes, 1)

    def forward(self, x):
        x1 = self.inc(x)
        x2 = self.__(x1)
        x3 = self.__(x2)
        x4 = self.__(x3)
        x = self.__(x4, x3)
        x = self.__(x, x2)
        x = self.__(x, x1)
        logits = self.__(x)
        return logits

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = UNet(n_channels=4, n_classes=5).to(device)





from torchsummary import summary

summary(model, input_size=(4, 96, 96))





import torch.optim as optim

def dice_coefficient(pred, target, smooth=1.):
    # One-hot encode the target labels
    target_one_hot = torch.zeros_like(pred, dtype=torch.float)
    target_one_hot.scatter_(1, target.unsqueeze(1), 1)

    # Calculate the Dice loss
    intersection = (pred * target_one_hot).sum(dim=(2, 3))
    cardinality = pred.sum(dim=(2, 3)) + target_one_hot.sum(dim=(2, 3))

    dice = (2. * intersection + smooth) / (cardinality + smooth)
    return dice.mean()

# Define the loss function
loss_function = nn.___(reduction='mean')

# Define the optimizer, learning rate and link it to the model

optimizer = optim.___(model.parameters(), lr=___)






from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import os
import albumentations as A

class BrainMRIDataset(Dataset):
    def __init__(self, file_list, data_path, transform=None):
        self.data_path = data_path
        self.transform = transform

        # Read the file_list and store the patient ids
        with open(file_list, 'r') as file:
            self.patient_ids = file.readlines()

        # Define the modalities
        self.modalities = ['_t1', '_t2', '_flair', '_t1ce', '_seg']

        # List all slices across patients and modalities
        self.slice_files = []
        for patient_id in self.patient_ids:
            patient_id = patient_id.strip()
            patient_folder = os.path.join(self.data_path, patient_id)
            slice_idx = 0
            while True:
                slice_files = [os.path.join(patient_folder, f"{patient_id}{modality}_z_{slice_idx}.nii.gz")
                               for modality in self.modalities]
                # Check if the slice files exist
                if not all(os.path.exists(slice_file) for slice_file in slice_files):
                    break
                self.slice_files.append(slice_files)
                slice_idx += 1

    def __len__(self):
        return len(self.slice_files)

    def __getitem__(self, idx):
        # Get the slice files for the given index
        slice_files = self.slice_files[idx]

        # Read the slices for each modality
        slices = []
        for slice_file in slice_files:
            image = sitk.ReadImage(slice_file)
            array = sitk.GetArrayFromImage(image)
            slices.append(array)

        # Stack the slices for all modalities
        data = np.stack(slices)

        # The last modality is the segmentation (label)
        labels = data[-1]

        # Select the other modalities as input
        data = data[:-1]
        if self.transform:
            augmented = self.transform(image=data, mask=labels)
            data = augmented['image']
            labels = augmented['mask']
        return data, labels

dataset_path = os.path.join(source, 'datasets/')
data_path = os.path.join(source, 'data/')

def normalize(array):

    mean = np.mean(array[array > 0])
    std = np.std(array[array > 0])
    array = (array - mean) / std
    array = np.clip(array, -5, 5)

    mini = np.min(array)
    maxi = np.max(array)

    array = (array - mini) / (maxi - mini)

    return array

transform = A.Compose([
    A.HorizontalFlip(),
    A.Rotate(limit = 10),
    A.ElasticTransform(),
])
# , is_check_shapes=False)


# Create the dataset
train_dataset = BrainMRIDataset(___, ___, transform=transform)
val_dataset = BrainMRIDataset(___, ___, transform=transform)
test_dataset = BrainMRIDataset(___, ___, transform=None)

# Setup the DataLoaders
train_dataloader = DataLoader(___, batch_size=___, shuffle=True, num_workers=0)
val_dataloader = DataLoader(___, batch_size=___, shuffle=False, num_workers=0)
test_dataloader = DataLoader(___, batch_size=___, shuffle=False, num_workers=0)





import matplotlib.pyplot as plt
import tqdm

# Number of epochs
num_epochs = 1

# Lists to keep track of metrics
train_losses = []
val_losses = []
val_accuracies = []
val_dice_coefficients = []
epoch = 0

# Training phase
model.train()

with tqdm.tqdm(total=len(train_dataloader), desc=f"Epoch {epoch + 1}/{num_epochs}", unit="batch") as pbar:
    for inputs, labels in train_dataloader:
        inputs, labels = inputs.float().to(device), labels.long().to(device)

        # Zero the parameter gradients
        optimizer.zero_grad()

        # Forward pass
        outputs = model(inputs)

        # Compute loss
        loss = loss_function(___, ___)

        # Backward pass and optimize
        loss.backward()
        torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)
        optimizer.step()

        train_losses.append(loss.item())
        pbar.update(1)
        pbar.set_postfix({"training_loss": loss.item()})

# Validation phase
print("Validation in progress...")
model.eval()
with torch.no_grad():
    for inputs, labels in val_dataloader:
        inputs, labels = inputs.float().to(device), labels.long().to(device)

        # Forward pass
        outputs = model(inputs)

        # Compute loss
        loss = loss_function(outputs, labels)
        val_losses.append(loss.item())

        # Compute accuracy
        _, preds = torch.max(outputs, 1)
        correct = (preds == labels).sum().item()
        total = labels.numel()
        accuracy = correct / total
        val_accuracies.append(accuracy)

        # Compute Dice Coefficient
        dice_coeff = dice_coefficient(preds, labels)
        val_dice_coefficients.append(dice_coeff.item())

# Calculate average validation loss, accuracy and Dice coefficient
train_loss = np.mean(train_losses)
val_loss = np.mean(val_losses)
val_accuracy = np.mean(val_accuracies)
val_dice_coefficient = np.mean(val_dice_coefficients)

print(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}, Validation Dice Coefficient: {val_dice_coefficient}")

# Plotting the training and validation loss
plt.figure(figsize=(10, 5))
plt.plot(___, label='Training Loss')
plt.xlabel('Iteration')
plt.ylabel('Metric Value')
plt.title('Training Loss vs Iteration')
plt.show()
plt.figure(figsize=(10, 5))
plt.plot(___, label='Validation Loss')
plt.plot(___, label='Validation accuracy')
plt.plot(___, label='Validation Dice')
plt.xlabel('Iteration')
plt.ylabel('Metric Value')
plt.title('Validation Metrics vs Iteration')
plt.show()








import matplotlib.pyplot as plt
import random
mods = ["t1", "t2", "flair", "t1ce"]

num_predictions = 10
n = 0
# Make predictions and plot them against the ground truth
while n < num_predictions:
    num_slice = random.randint(0, 870)
    inputs = [np.load(os.path.join(source, 'test/input_{}_{}.npy'.format(num_slice,mods[j]))) for j in range(4)]
    labels = np.load(os.path.join(source, 'test/label_{}.npy'.format(num_slice)))
    predictions = np.load(os.path.join(source, 'test/prediction_{}.npy'.format(num_slice)))
    if labels.sum() > 0:

        # Plot the input modalities
        plt.figure(figsize=(20, 10))
        for i in range(4):
            plt.subplot(1, 6, i+1)
            plt.imshow(___, cmap='gray')
            plt.title(mods[i])
            plt.axis('off')
        # Plot the predicted mask and the ground truth
        plt.subplot(1, 6, 5)
        plt.imshow(___)
        plt.title('Predicted Mask')
        plt.axis('off')

        plt.subplot(1, 6, 6)
        plt.imshow(___)
        plt.title('Ground Truth')
        plt.axis('off')

        plt.show()
        n+=1





from sklearn.metrics import confusion_matrix
test_dataloader = DataLoader(test_dataset, batch_size=int(len(test_dataset)/10), shuffle=False, num_workers=0)
# print the size of the test dataset
# Create arrays to store the metrics for each category
sensitivities = []
specificities = []
dices = []

# Define the label categories
categories = [(1, 2, 4), (1, 4), (4,)]
mods = ["t1", "t2", "flair", "t1ce"]
# Calculate metrics for each category
for category in categories:
    # Initialize counters
    TP = FP = FN = TN = 0

    # Iterate through the test set
    for i in range(int(len(os.listdir(os.path.join(source, 'test/')))/6)):

        labels = np.load(os.path.join(source, 'test/label_{}.npy'.format(i)))
        predictions = np.load(os.path.join(source, 'test/prediction_{}.npy'.format(i)))


        # Update counters
        c_matrix = confusion_matrix((labels[..., np.newaxis] == category).ravel(), (predictions[..., np.newaxis] == category).ravel())
        # handle the case if there is only one label so the confusion matrix is 1x1
        if c_matrix.shape == (1, 1):
            c_matrix = np.array([[c_matrix[0, 0], 0], [0, 0]])

        TP += c_matrix[1, 1]
        FP += c_matrix[0, 1]
        FN += c_matrix[1, 0]
        TN += c_matrix[0, 0]

    # Calculate metrics
    sensitivity = ___
    specificity = ___
    dice = ___

    # Append to results
    sensitivities.append(sensitivity)
    specificities.append(specificity)
    dices.append(dice)

# Display results in a table
import pandas as pd

data = {'Category': ['Whole Tumor', 'Tumor Core', 'Enhancing Tumor'],
        'Sensitivity': ___,
        'Specificity': ___,
        'Dice Coefficient': ___}

df = pd.DataFrame(data)
print(df)









import numpy as np
import os

path = os.path.join(source, 'datasets/')

train_set = np.loadtxt(path + 'train.txt', dtype=str)
validation_set = np.loadtxt(path + 'val.txt', dtype=str)
test_set = np.loadtxt(path + 'test.txt', dtype=str)

# Train_set, validation_set, and test_set are lists of patients
print('Train Set - First 5 Patients:')
print(train_set[:5])

train_size = len(train_set)
validation_size = len(validation_set)
test_size = len(test_set)

print('Train Set Size:', train_size)
print('Validation Set Size:', validation_size)
print('Test Set Size:', test_size)





import os
data_folder = os.path.join(source, 'data/')

patients = os.listdir(data_folder)
print('First 5 Patients in the Data Folder:')
print(patients[:5])

data_folder_length = len(patients)
print('Data Folder Length:', data_folder_length)

selected_patient = 'BraTS19_2013_0_1/'
patient_folder = os.path.join(data_folder, selected_patient)
images = os.listdir(patient_folder)
num_images = len(images)
print('Number of Images in Patient Folder:', num_images)

num_slices = len(images) /5
print('Number of Z Slices for', selected_patient, ':', num_slices)

print('First 5 Images of', selected_patient, ':')
for image in images[:5]:
    print(image)





import SimpleITK as sitk
import os

orig_data_path = os.path.join(source, 'origin_data/')

patients = ['BraTS19_CBICA_ANP_1', 'BraTS19_CBICA_AWV_1', 'BraTS19_TCIA01_131_1', 'BraTS19_TCIA10_442_1']
modalities = ['_t1', '_t2', '_flair', 't1ce', 'seg']
suffix = '.nii.gz'

patient = patients[0]
modality = modalities[0]

patient_folder = os.path.join(orig_data_path, patient)

# Use SimpleITK to open the NIfTI image
image_path = os.path.join(patient_folder, patient + modality + suffix)
image = sitk.ReadImage(image_path)

# Print the image type
print('Image Type:', type(image))

# Print geometrical information
print('Image Direction:', image.GetDirection())
print('Image Spacing:', image.GetSpacing())
print('Image Origin:', image.GetOrigin())

# Get the pixel value at coordinate (0, 0, 0)
print('Pixel Value at (0, 0, 0):', image.GetPixel(0, 0, 0))

# Get all the metadata information
metadata = image.GetMetaDataKeys()
print('Metadata:')
for key in metadata:
    value = image.GetMetaData(key)
    print('{}: {}'.format(key, value))

# Convert the SimpleITK image to a NumPy array
array = sitk.GetArrayFromImage(image)
print('Array Type:', type(array))
print('Array Shape:', array.shape)
print('Value at (0, 0, 0) in the Array:', array[0, 0, 0])





import matplotlib.pyplot as plt

orig_data_path = os.path.join(source, 'origin_data/')

patient = patients[0]
modality = modalities[0]
patient_folder = os.path.join(orig_data_path,patient)
# We use the librairy sitk to open the nifti images
image = sitk.ReadImage(os.path.join(patient_folder, patient + modality + suffix))
orig_array = sitk.GetArrayFromImage(image)
print('Orig array shape : {}'.format(orig_array.shape))


data_path = os.path.join(source, 'data')
patient_folder = os.path.join(data_path,patient)
z_slice = 35
path = os.path.join(patient_folder, patient + modality + '_z_' + str(z_slice) + suffix)
image = sitk.ReadImage(path)
processed_array = sitk.GetArrayFromImage(image)
print('Processed array shape : {}'.format(processed_array.shape))

plt.subplot(1, 2, 1)
plt.imshow(orig_array[z_slice*2, :, :], cmap='gray')
plt.title('Original array')
plt.subplot(1, 2, 2)
plt.imshow(processed_array, cmap='gray')
plt.title('Processed array')





import torch
from torch import nn

def double_conv(in_channels, out_channels):
            return nn.Sequential(
                nn.Conv2d(in_channels, out_channels, 3, padding=1),
                nn.ReLU(inplace=True),
                nn.Conv2d(out_channels, out_channels, 3, padding=1),
                nn.ReLU(inplace=True),
                nn.Dropout(0.5)
            )

def down(in_channels, out_channels):
    return nn.Sequential(
        nn.MaxPool2d(2),
        double_conv(in_channels, out_channels)
    )

class up_block(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(up_block, self).__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.upsample = nn.Sequential(nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),
                                       nn.Conv2d(in_channels,in_channels//2, 2, padding="same"))
        self.up_conv = double_conv(self.in_channels, self.out_channels)

    def forward(self, x, x_skip):
        x = self.upsample(x)
        x = torch.cat([x, x_skip], dim=1)
        x = self.up_conv(x)
        return x

start_channel = 16
class UNet(nn.Module):
    def __init__(self, n_channels, n_classes):
        super(UNet, self).__init__()
        self.n_channels = n_channels
        self.n_classes = n_classes

        # Define blocks of convolutions
        self.inc = double_conv(n_channels, start_channel)
        self.down1 = down(start_channel, start_channel*2)
        self.down2 = down(start_channel*2, start_channel*4)
        self.down3 = down(start_channel*4, start_channel*8)
        self.up1 = up_block(start_channel*8, start_channel*4)
        self.up2 = up_block(start_channel*4, start_channel*2)
        self.up3 = up_block(start_channel*2, start_channel)
        self.outc = nn.Conv2d(start_channel, n_classes, 1)

    def forward(self, x):
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x = self.up1(x4, x3)
        x = self.up2(x, x2)
        x = self.up3(x, x1)
        logits = self.outc(x)
        return logits

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = UNet(n_channels=4, n_classes=5).to(device)





from torchsummary import summary

summary(model, input_size=(4, 96, 96))


torch.cuda.is_available()





import torch.optim as optim

# Define the dice coefficient metric for validation
def dice_coefficient(pred, target, smooth=1.):
    # One-hot encode the target labels
    target_one_hot = torch.zeros_like(pred, dtype=torch.float)
    target_one_hot.scatter_(1, target.unsqueeze(1), 1)

    # Calculate the Dice loss
    intersection = (pred * target_one_hot).sum(dim=(2, 3))
    cardinality = pred.sum(dim=(2, 3)) + target_one_hot.sum(dim=(2, 3))

    dice = (2. * intersection + smooth) / (cardinality + smooth)
    return dice.mean()

# Define the loss function
loss_function = nn.CrossEntropyLoss(reduction='mean')

# Define the optimizer, learning rate and link it to the model
optimizer = optim.Adam(model.parameters(), lr=0.0005)






from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import os
import albumentations as A

class BrainMRIDataset(Dataset):
    def __init__(self, file_list, data_path, transform=None):
        self.data_path = data_path
        self.transform = transform

        # Read the file_list and store the patient ids
        with open(file_list, 'r') as file:
            self.patient_ids = file.readlines()

        # Define the modalities
        self.modalities = ['_t1', '_t2', '_flair', '_t1ce', '_seg']

        # List all slices across patients and modalities
        self.slice_files = []
        for patient_id in self.patient_ids:
            patient_id = patient_id.strip()
            patient_folder = os.path.join(self.data_path, patient_id)
            slice_idx = 0
            while True:
                slice_files = [os.path.join(patient_folder, f"{patient_id}{modality}_z_{slice_idx}.nii.gz")
                               for modality in self.modalities]
                # Check if the slice files exist
                if not all(os.path.exists(slice_file) for slice_file in slice_files):
                    break
                self.slice_files.append(slice_files)
                slice_idx += 1

    def __len__(self):
        return len(self.slice_files)

    def __getitem__(self, idx):
        # Get the slice files for the given index
        slice_files = self.slice_files[idx]

        # Read the slices for each modality
        slices = []
        for slice_file in slice_files:
            image = sitk.ReadImage(slice_file)
            array = sitk.GetArrayFromImage(image)
            slices.append(array)

        # Stack the slices for all modalities
        data = np.stack(slices)

        # The last modality is the segmentation (label)
        labels = data[-1]

        # Select the other modalities as input
        data = data[:-1]
        if self.transform:
            augmented = self.transform(image=data, mask=labels)
            data = augmented['image']
            labels = augmented['mask']
        return data, labels


dataset_path = os.path.join(source, 'datasets/')
data_path = os.path.join(source, 'data/')

def normalize(array):

    mean = np.mean(array[array > 0])
    std = np.std(array[array > 0])
    array = (array - mean) / std
    array = np.clip(array, -5, 5)

    mini = np.min(array)
    maxi = np.max(array)

    array = (array - mini) / (maxi - mini)

    return array

transform = A.Compose([
    A.HorizontalFlip(),
    A.Rotate(limit = 10),
]
, is_check_shapes=False)



# Create the dataset
train_dataset = BrainMRIDataset(os.path.join(dataset_path, 'train.txt'), data_path, transform=transform)
val_dataset = BrainMRIDataset(os.path.join(dataset_path, 'val.txt'), data_path, transform=transform)
test_dataset = BrainMRIDataset(os.path.join(dataset_path, 'test.txt'), data_path, transform=None)

batch_size = 128
# Setup the DataLoaders
train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)





import matplotlib.pyplot as plt
import tqdm

# Number of epochs
num_epochs = 10

# Lists to keep track of metrics
train_losses = []
val_losses = []
val_accuracies = []
val_dice_coefficients = []
epoch = 0

# Training phase
model.train()

with tqdm.tqdm(total=len(train_dataloader), desc=f"Epoch {epoch + 1}/{num_epochs}", unit="batch") as pbar:
    for inputs, labels in train_dataloader:
        inputs, labels = inputs.float().to(device), labels.long().to(device)
        # Zero the parameter gradients
        optimizer.zero_grad()

        # Forward pass
        outputs = model(inputs)

        # Compute loss
        loss = loss_function(outputs, labels)

        # Backward pass and optimize
        loss.backward()
        optimizer.step()

        train_losses.append(loss.item())
        pbar.update(1)
        pbar.set_postfix({"training_loss": loss.item()})

# Validation phase
print("Validation in progress...")
model.eval()
with torch.no_grad():
    for inputs, labels in val_dataloader:
        inputs, labels = inputs.float().to(device), labels.long().to(device)

        # Forward pass
        outputs = model(inputs)

        # Compute loss
        loss = loss_function(outputs, labels)
        val_losses.append(loss.item())

        # Compute accuracy
        _, preds = torch.max(outputs, 1)
        correct = (preds == labels).sum().item()
        total = labels.numel()
        accuracy = correct / total
        val_accuracies.append(accuracy)

        # # Compute Dice Coefficient
        # dice_coeff = dice_coefficient(preds, labels)
        # val_dice_coefficients.append(dice_coeff.item())

# Calculate average validation loss, accuracy and Dice coefficient
train_loss = np.mean(train_losses)
val_loss = np.mean(val_losses)
val_accuracy = np.mean(val_accuracies)
# val_dice_coefficient = np.mean(val_dice_coefficients)
val_dice_coefficient = 0

print(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}, Validation Dice Coefficient: {val_dice_coefficient}")

# Plotting the training and validation loss
plt.figure(figsize=(10, 5))
plt.plot(train_losses, label='Training Loss')
plt.xlabel('Iteration')
plt.ylabel('Metric Value')
plt.title('Training Loss vs Iteration')
plt.show()
plt.figure(figsize=(10, 5))
plt.plot(val_losses, label='Validation Loss')
plt.plot(val_accuracies, label='Validation accuracy')
# plt.plot(val_dice_coefficients, label='Validation Dice')
plt.xlabel('Iteration')
plt.ylabel('Metric Value')
plt.title('Validation Metrics vs Iteration')
plt.show()





torch.cuda.is_available()





import matplotlib.pyplot as plt
import random
mods = ["t1", "t2", "flair", "t1ce"]

num_predictions = 10
n = 0
# Make predictions and plot them against the ground truth
while n < num_predictions:
    num_slice = random.randint(0, 870)
    inputs = [np.load(os.path.join(source, 'test/input_{}_{}.npy'.format(num_slice,mods[j]))) for j in range(4)]
    labels = np.load(os.path.join(source, 'test/label_{}.npy'.format(num_slice)))
    predictions = np.load(os.path.join(source, 'test/prediction_{}.npy'.format(num_slice)))
    if labels.sum() > 0:

        # Plot the input modalities
        plt.figure(figsize=(20, 10))
        for i in range(4):
            plt.subplot(1, 6, i+1)
            plt.imshow(inputs[i], cmap='gray')
            plt.title(mods[i])
            plt.axis('off')
        # Plot the predicted mask and the ground truth
        plt.subplot(1, 6, 5)
        plt.imshow(predictions)
        plt.title('Predicted Mask')
        plt.axis('off')

        plt.subplot(1, 6, 6)
        plt.imshow(labels)
        plt.title('Ground Truth')
        plt.axis('off')

        plt.show()
        n+=1





from sklearn.metrics import confusion_matrix
test_dataloader = DataLoader(test_dataset, batch_size=int(len(test_dataset)/10), shuffle=False, num_workers=0)
# Create arrays to store the metrics for each category
sensitivities = []
specificities = []
dices = []

# Define the label categories
categories = [(1, 2, 4), (1, 4), (4,)]
mods = ["t1", "t2", "flair", "t1ce"]
# Calculate metrics for each category
for category in categories:
    # Initialize counters
    TP = FP = FN = TN = 0

    # Iterate through the test set
    for i in range(int(len(os.listdir(os.path.join(source, 'test/')))/6)):

        labels = np.load(os.path.join(source, 'test/label_{}.npy'.format(i)))
        predictions = np.load(os.path.join(source, 'test/prediction_{}.npy'.format(i)))


        # Update counters
        c_matrix = confusion_matrix((labels[..., np.newaxis] == category).ravel(), (predictions[..., np.newaxis] == category).ravel())
        # handle the case if there is only one label so the confusion matrix is 1x1
        if c_matrix.shape == (1, 1):
            c_matrix = np.array([[c_matrix[0, 0], 0], [0, 0]])
        TP += c_matrix[1, 1]
        FP += c_matrix[0, 1]
        FN += c_matrix[1, 0]
        TN += c_matrix[0, 0]

    # Calculate metrics
    sensitivity = TP / (TP + FN)
    specificity = TN / (TN + FP)
    dice = 2 * TP / (2 * TP + FP + FN)

    # Append to results
    sensitivities.append(sensitivity)
    specificities.append(specificity)
    dices.append(dice)

# Display results in a table
import pandas as pd

data = {'Category': ['Whole Tumor', 'Tumor Core', 'Enhancing Tumor'],
        'Sensitivity': sensitivities,
        'Specificity': specificities,
        'Dice Coefficient': dices}

df = pd.DataFrame(data)
print(df)

